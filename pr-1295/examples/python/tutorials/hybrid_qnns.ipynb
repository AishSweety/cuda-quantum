{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Quantum Neural Networks \n",
    "\n",
    "The example below highlights a hybrid quantum neural network workflow with CUDA Quantum and Pytorch where both layers are GPU accelerated to maximise performance. \n",
    "\n",
    "\n",
    "<img src=\"images/hybrid.png\" alt=\"hybrid\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform binary classification on the MNIST dataset where data flows through the neural network architecture to the quantum circuit whose output is used to classify hand written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU utilities\n",
    "\n",
    "cudaq.set_target(\"nvidia\")  # Set CUDAQ to run on GPU's\n",
    "\n",
    "torch.cuda.is_available(\n",
    ")  # If this is True then the NVIDIA drivers are correctly installed\n",
    "\n",
    "torch.cuda.device_count()  # Counts the number of GPU's available\n",
    "\n",
    "torch.cuda.current_device()\n",
    "\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 72148113.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 79537553.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 45882038.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 15252625.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training set.\n",
    "sample_count = 140\n",
    "\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "\n",
    "# Leaving only labels 0 and 1.\n",
    "idx = np.append(\n",
    "    np.where(X_train.targets == 0)[0][:sample_count],\n",
    "    np.where(X_train.targets == 1)[0][:sample_count],\n",
    ")\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)\n",
    "\n",
    "# Test set.\n",
    "sample_count = 70\n",
    "\n",
    "X_test = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "idx = np.append(\n",
    "    np.where(X_test.targets == 0)[0][:sample_count],\n",
    "    np.where(X_test.targets == 1)[0][:sample_count],\n",
    ")\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumFunction(Function):\n",
    "    \"\"\"This class defines the quantum circuit structure, the forward and the backward method.\"\"\"\n",
    "\n",
    "    def __init__(self, qubit_count: int, hamiltonian: cudaq.SpinOperator):\n",
    "        \"\"\"Define the quantum circuit in CUDA Quantum\"\"\"\n",
    "\n",
    "        kernel, thetas = cudaq.make_kernel(list)\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.theta = thetas\n",
    "        self.hamiltonian = hamiltonian\n",
    "\n",
    "        qubits = kernel.qalloc(qubit_count)\n",
    "\n",
    "        self.kernel.h(qubits)\n",
    "\n",
    "        # Variational gate parameters which are optimised during training.\n",
    "        kernel.ry(thetas[0], qubits[0])\n",
    "        kernel.rx(thetas[1], qubits[0])\n",
    "\n",
    "    def run(self, thetas: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Excetute the quantum circuit to output an expectation value\"\"\"\n",
    "\n",
    "        expectation = torch.tensor(cudaq.observe(self.kernel, self.hamiltonian,\n",
    "                                                 thetas).expectation(),\n",
    "                                   device=device)\n",
    "\n",
    "        return expectation\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, thetas: torch.tensor, quantum_circuit,\n",
    "                shift) -> torch.tensor:\n",
    "\n",
    "        # Save shift and quantum_circuit in context to use in backward.\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        # Calculate expectation value.\n",
    "        expectation = ctx.quantum_circuit.run(thetas)\n",
    "\n",
    "        ctx.save_for_backward(thetas, expectation)\n",
    "\n",
    "        return expectation\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"Backward pass computation via finite difference parameter shift\"\"\"\n",
    "\n",
    "        thetas, expectation = ctx.saved_tensors\n",
    "\n",
    "        gradients = torch.zeros(len(thetas), device=device)\n",
    "\n",
    "        for i in range(len(thetas)):\n",
    "            shift_right = torch.clone(thetas)\n",
    "\n",
    "            shift_right[i] += ctx.shift\n",
    "\n",
    "            shift_left = torch.clone(thetas)\n",
    "\n",
    "            shift_left[i] -= ctx.shift\n",
    "\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right)\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left)\n",
    "\n",
    "            gradients[i] = (expectation_right -\n",
    "                            expectation_left) / 2 * ctx.shift\n",
    "\n",
    "        return gradients * grad_output.float(), None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Encapsulates a quantum circuit and a quantum function into a quantum layer\"\"\"\n",
    "\n",
    "    def __init__(self, qubit_count: int, hamiltonian, shift: torch.tensor):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "\n",
    "        # 1 qubit quantum circuit.\n",
    "        self.quantum_circuit = QuantumFunction(qubit_count, hamiltonian)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "        ans = QuantumFunction.apply(input, self.quantum_circuit, self.shift)\n",
    "\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit_count = 1\n",
    "hamiltonian = spin.z(0)\n",
    "shift = torch.tensor(np.pi / 2)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Neural network structure.\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(\n",
    "            64, 2\n",
    "        )  # Output a 2D tensor since we have 2 variational parameters in our quantum circuit.\n",
    "        self.hybrid = QuantumLayer(\n",
    "            qubit_count, hamiltonian, shift\n",
    "        )  # Input is the magnitude of the parameter shifts to calculate gradients.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x).reshape(\n",
    "            -1\n",
    "        )  # Reshapes required to satisfy input dimensions to CUDA Quantum.\n",
    "        x = self.hybrid(x).reshape(-1)\n",
    "\n",
    "        return torch.cat((x, 1 - x), -1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "can not handle conversion of python type <class 'torch.Tensor'> to mlir type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Forward pass.\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m output \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Calculating loss.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m loss \u001b[39m=\u001b[39m loss_func(output, target)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc1(x))\n\u001b[1;32m     31\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m     32\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     33\u001b[0m )  \u001b[39m# Reshapes required to satisfy input dimensions to CUDA Quantum.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhybrid(x)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat((x, \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m x), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mQuantumLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     ans \u001b[39m=\u001b[39m QuantumFunction\u001b[39m.\u001b[39;49mapply(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquantum_circuit, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshift)\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m ans\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mQuantumFunction.forward\u001b[0;34m(ctx, thetas, quantum_circuit, shift)\u001b[0m\n\u001b[1;32m     37\u001b[0m ctx\u001b[39m.\u001b[39mquantum_circuit \u001b[39m=\u001b[39m quantum_circuit\n\u001b[1;32m     39\u001b[0m \u001b[39m# Calculate expectation value.\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m expectation \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39;49mquantum_circuit\u001b[39m.\u001b[39;49mrun(thetas)\n\u001b[1;32m     42\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(thetas, expectation)\n\u001b[1;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m expectation\n",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m, in \u001b[0;36mQuantumFunction.run\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, thetas: torch\u001b[39m.\u001b[39mtensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mtensor:\n\u001b[1;32m     23\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Excetute the quantum circuit to output an expectation value\"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     expectation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(cudaq\u001b[39m.\u001b[39;49mobserve(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhamiltonian,\n\u001b[1;32m     26\u001b[0m                                              thetas)\u001b[39m.\u001b[39mexpectation(),\n\u001b[1;32m     27\u001b[0m                                device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m expectation\n",
      "File \u001b[0;32m/usr/local/cudaq/cudaq/runtime/observe.py:110\u001b[0m, in \u001b[0;36mobserve\u001b[0;34m(kernel, spin_operator, shots_count, noise_model, execution, *args)\u001b[0m\n\u001b[1;32m    108\u001b[0m ctx\u001b[39m.\u001b[39msetSpinOperator(localOp)\n\u001b[1;32m    109\u001b[0m cudaq_runtime\u001b[39m.\u001b[39msetExecutionContext(ctx)\n\u001b[0;32m--> 110\u001b[0m kernel(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    111\u001b[0m res \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mresult\n\u001b[1;32m    112\u001b[0m cudaq_runtime\u001b[39m.\u001b[39mresetExecutionContext()\n",
      "File \u001b[0;32m/usr/local/cudaq/cudaq/kernel/kernel_builder.py:979\u001b[0m, in \u001b[0;36mPyKernel.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    977\u001b[0m processedArgs \u001b[39m=\u001b[39m []\n\u001b[1;32m    978\u001b[0m \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(args):\n\u001b[0;32m--> 979\u001b[0m     mlirType \u001b[39m=\u001b[39m mlirTypeFromPyType(\u001b[39mtype\u001b[39;49m(arg), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mctx)\n\u001b[1;32m    980\u001b[0m     \u001b[39mif\u001b[39;00m mlirType \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlirArgTypes[i]:\n\u001b[1;32m    981\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minvalid runtime arg type (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    982\u001b[0m             mlirType, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlirArgTypes[i]))\n",
      "File \u001b[0;32m/usr/local/cudaq/cudaq/kernel/utils.py:126\u001b[0m, in \u001b[0;36mmlirTypeFromPyType\u001b[0;34m(argType, ctx, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(argInstance, Callable):\n\u001b[1;32m    124\u001b[0m         \u001b[39mreturn\u001b[39;00m cc\u001b[39m.\u001b[39mCallableType\u001b[39m.\u001b[39mget(ctx, argInstance\u001b[39m.\u001b[39margTypes)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    127\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcan not handle conversion of python type \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to mlir type.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    128\u001b[0m         argType))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: can not handle conversion of python type <class 'torch.Tensor'> to mlir type."
     ]
    }
   ],
   "source": [
    "# We move our model to the CUDA device to minimise data transfer between GPU and CPU.\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_func = nn.NLLLoss().to(device)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "epoch_loss = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # Batch training.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass.\n",
    "        output = model(data).to(device)\n",
    "\n",
    "        # Calculating loss.\n",
    "        loss = loss_func(output, target).to(device)\n",
    "\n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the weights.\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    epoch_loss.append(batch_loss / batch_idx)\n",
    "\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(\n",
    "        100.0 * (epoch + 1) / epochs, epoch_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_loss)\n",
    "plt.title(\"Hybrid NN Training Convergence\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "\n",
    "plt.ylabel(\"Neg Log Likelihood Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on the test set.\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data).to(device)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    print(\"Performance on test data:\\n\\tAccuracy: {:.1f}%\".format(\n",
    "        correct / len(test_loader) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
